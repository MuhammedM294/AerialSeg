{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import albumentations as A\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_size = 512\n",
    "\n",
    "class SegmentationDataset(Dataset[any]):\n",
    "    \"\"\"\n",
    "    A PyTorch dataset class for segmentation task.\n",
    "\n",
    "    This class represents a dataset used for the segmentation task, where each sample consists of an image and its corresponding mask. \n",
    "    It inherits from the PyTorch `Dataset` class.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A Pandas DataFrame containing the image and label paths.\n",
    "        train (bool): Specifies whether the dataset is for training (True) or testing (False).\n",
    "        transform (torchvision.transforms.Normalize, optional): A transformation to be applied to the image. Defaults to None.\n",
    "        augment (albumentations.Compose, optional): A composition of augmentations to be applied to both the image and mask. Defaults to None.\n",
    "\n",
    "    Attributes:\n",
    "        train (bool): Indicates whether the dataset is for training or testing.\n",
    "        transform (torchvision.transforms.Normalize): The transformation applied to the image.\n",
    "        augment (albumentations.Compose): The composition of augmentations applied to the image and mask.\n",
    "        df (pd.DataFrame): The subset of the DataFrame that corresponds to the train or test split.\n",
    "\n",
    "    Methods:\n",
    "        __len__():\n",
    "            Returns the length of the dataset.\n",
    "\n",
    "        __getitem__(idx:int):\n",
    "            Retrieves the image and mask at the given index.\n",
    "\n",
    "        get_image(idx:int):\n",
    "            Read the image at the given index from the file.\n",
    "\n",
    "        get_mask(idx:int):\n",
    "            Read the mask at the given index from the file.\n",
    "\n",
    "        preprocess(image:np.array, mask:np.array):\n",
    "            Preprocesses the image and mask data.\n",
    "\n",
    "    Returns:\n",
    "        A PyTorch dataset object for the segmentation task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df:pd.DataFrame, train:bool, transform:transforms.Normalize = None, augment:A.Compose = None):\n",
    "     \n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "        if self.train:\n",
    "            self.df = df[df['split'] == 'train']\n",
    "        else:\n",
    "            self.df = df[df['split'] == 'test']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx:int):\n",
    "        image = self.get_image(idx)\n",
    "        mask = self.get_mask(idx)\n",
    "        image , mask  = self.preprocess(image, mask)\n",
    "    \n",
    "        return image.to(device) , mask.to(device)\n",
    "    \n",
    "    def get_image(self, idx:int):\n",
    "        image_path = '../data/roads/' + self.df.iloc[idx, 4]\n",
    "        image = cv2.imread(image_path)[:,:,::-1]\n",
    "        image = cv2.resize(image/255., (image_size, image_size))\n",
    "        return image\n",
    "    \n",
    "    def get_mask(self, idx:int):\n",
    "        mask_path = '../data/roads/' + self.df.iloc[idx, 5]\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask/255, (image_size, image_size))\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        return mask\n",
    "    \n",
    "    def preprocess(self, image:np.array, mask:np.array):\n",
    "        \n",
    "        if self.augment:\n",
    "            data = self.augment(image = image, mask = mask)\n",
    "            image = data['image']\n",
    "            mask = data['mask']\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2,0,1)\n",
    "        mask = torch.tensor(mask, dtype=torch.float32).permute(2,0,1)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "\n",
    "def train_augmentation():\n",
    "    \"\"\"\n",
    "    Creates an augmentation pipeline for training images.\n",
    "\n",
    "    Returns:\n",
    "        A.Compose: An instance of the `A.Compose` class representing the augmentation pipeline.\n",
    "\n",
    "    Example:\n",
    "        augmentation = train_augmentation()(image=image, mask=mask)\n",
    "        augmented_image = augmentation['image']\n",
    "        augmented_mask = augmentation['mask']\n",
    "    \"\"\"\n",
    "    return  A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=0.9,\n",
    "                            border_mode=cv2.BORDER_REFLECT),\n",
    "        \n",
    "    ])\n",
    "\n",
    "def transform():\n",
    "    \"\"\"\n",
    "    Returns a transformation function that normalizes an input image.\n",
    "\n",
    "    Returns:\n",
    "        torchvision.transforms.Normalize: An instance of the `torchvision.transforms.Normalize` class.\n",
    "\n",
    "    Example:\n",
    "        transform_func = transform()\n",
    "        transformed_image = transform_func(image)\n",
    "    \"\"\"\n",
    "    return transforms.Normalize(mean=[0.485,0.456, 0.406],std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
